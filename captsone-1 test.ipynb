{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308c1777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (2.119.0)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: google-auth<3.0.0.dev0,>=1.19.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.28.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-api-python-client) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-api-python-client) (2.17.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.62.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.3)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0.dev0,>=1.19.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2023.11.17)\n",
      "Requirement already satisfied: pymongo in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (4.6.2)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from pymongo) (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-api-python-client\n",
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa09ff68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: streamlit in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (1.31.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (1.7.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (8.0.4)\n",
      "Requirement already satisfied: importlib-metadata<8,>=1.4 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (1.24.3)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (2.0.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (10.0.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (4.25.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (4.7.1)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (3.1.42)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (6.3.2)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from importlib-metadata<8,>=1.4->streamlit) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\cbmit\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3bbeb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import pymongo\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import streamlit as sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67e013e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b19c3576",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key='AIzaSyBJ5nl-6uIwq2GlAy6nRJoH9C-Utpu6raw'\n",
    "youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99737fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_data(channel_id):\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=channel_id)\n",
    "\n",
    "    response = request.execute()\n",
    "    \n",
    "    for i in response['items']:\n",
    "        data=dict(channel_name=i['snippet']['title'],channel_id=i['id'],\n",
    "              subscriber_count=i['statistics']['subscriberCount'],\n",
    "             channel_views=i['statistics']['viewCount'],\n",
    "             channel_discription=i['snippet']['description'],\n",
    "             playlist_id=i['contentDetails']['relatedPlaylists']['uploads'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b4218c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'JK ',\n",
       " 'channel_id': 'UC_HZY9d5wJ-MEiuq6vhx8hg',\n",
       " 'subscriber_count': '761000',\n",
       " 'channel_views': '83449978',\n",
       " 'channel_discription': 'ü§ì\\n',\n",
       " 'playlist_id': 'UU_HZY9d5wJ-MEiuq6vhx8hg'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel1_details=get_channel_data('UC_HZY9d5wJ-MEiuq6vhx8hg')\n",
    "channel1_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ff33c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'JayKay',\n",
       " 'channel_id': 'UCCAqSErX2Rp-QADZNPfPK6A',\n",
       " 'subscriber_count': '78100',\n",
       " 'channel_views': '1097713',\n",
       " 'channel_discription': 'more random videos ‚ùó‚ùó üó£ üó£',\n",
       " 'playlist_id': 'UUCAqSErX2Rp-QADZNPfPK6A'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel2_details=get_channel_data('UCCAqSErX2Rp-QADZNPfPK6A')\n",
    "channel2_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b403250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'Vj Siddhu Vlogs',\n",
       " 'channel_id': 'UCJcCB-QYPIBcbKcBQOTwhiA',\n",
       " 'subscriber_count': '1880000',\n",
       " 'channel_views': '247236168',\n",
       " 'channel_discription': 'Hello guys! Welcome to my channel! !\\n\\nMy channel will take you into the details of my life and give a glimpse of what inspires me to do what I do. \\n\\nGet ready to watch my latest vlogs depicting life in detail that will make you slow down and enjoy life a little better. Subscribe to my channel and stay connected!  \\n\\nFor Business inquiries please contact us :7200571056\\nGmail : vjsidduvlogsadv@gmail.com \\n______________________________\\n\\nDigital Partner - Divo\\nDivo is one of the leading digital media companies in South India working with brands and content creators across genres.\\n',\n",
       " 'playlist_id': 'UUJcCB-QYPIBcbKcBQOTwhiA'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel3_details=get_channel_data('UCJcCB-QYPIBcbKcBQOTwhiA')\n",
    "channel3_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddc918a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'Yeah Tube',\n",
       " 'channel_id': 'UCOc9_2EiEc6XrHZZ1Gupv8g',\n",
       " 'subscriber_count': '168000',\n",
       " 'channel_views': '15276269',\n",
       " 'channel_discription': 'üëç\\n',\n",
       " 'playlist_id': 'UUOc9_2EiEc6XrHZZ1Gupv8g'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel4_details=get_channel_data('UCOc9_2EiEc6XrHZZ1Gupv8g')\n",
    "channel4_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c4ab59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'Eruma Saani',\n",
       " 'channel_id': 'UCPyFYlqbkxkWX_dWCg0eekA',\n",
       " 'subscriber_count': '3680000',\n",
       " 'channel_views': '449146737',\n",
       " 'channel_discription': 'Eruma Saani is a new channel started by a bunch of crazy shit shells. Please subscribe to our channel for crazy and enthusiastic content.\\n\\nFor brand collaboration & advertising drop a mail to erumasaaniads@gmail.com\\n',\n",
       " 'playlist_id': 'UUPyFYlqbkxkWX_dWCg0eekA'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel5_details=get_channel_data('UCPyFYlqbkxkWX_dWCg0eekA')\n",
    "channel5_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87158f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'Plip Plip',\n",
       " 'channel_id': 'UCbq544I2cTyvcrZwmnSIj9Q',\n",
       " 'subscriber_count': '1110000',\n",
       " 'channel_views': '115871960',\n",
       " 'channel_discription': 'Movie Roasts, Commentary, Meme Reviews, Subreddit Raids, Sketches, Vlogs, Gameplay, Cooking Tutorials are some of the stuffs we do.',\n",
       " 'playlist_id': 'UUbq544I2cTyvcrZwmnSIj9Q'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel6_details=get_channel_data('UCbq544I2cTyvcrZwmnSIj9Q')\n",
    "channel6_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f02c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'Jordindian',\n",
       " 'channel_id': 'UCYLS9TSah19IsB8yyUpiDzg',\n",
       " 'subscriber_count': '2940000',\n",
       " 'channel_views': '740811119',\n",
       " 'channel_discription': 'Two friends, one from Jordan and the other from India came together and said, \"Hey... Let‚Äôs make some videos\". Hence the journey of Jordindian began. \\nIf you smile, laugh and/or lose your mind, we\\'re pretty much doing what we set out to do... Have fun and entertain. \\n\\nEnjoy! \\n\\nEmail - thejordindian@gmail.com\\nFOLLOW US ON\\nFACEBOOK - Jordindian\\nINSTAGRAM - @thejordindian\\nTWITTER - @thejordindian',\n",
       " 'playlist_id': 'UUYLS9TSah19IsB8yyUpiDzg'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel7_details=get_channel_data('UCYLS9TSah19IsB8yyUpiDzg')\n",
    "channel7_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5859191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'Empty Hand',\n",
       " 'channel_id': 'UC8_aMwsn53tncdH-5iLu8-w',\n",
       " 'subscriber_count': '1750000',\n",
       " 'channel_views': '326196156',\n",
       " 'channel_discription': 'Hi...Welcome to Empty Hand YouTube Channel...',\n",
       " 'playlist_id': 'UU8_aMwsn53tncdH-5iLu8-w'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel8_details=get_channel_data('UC8_aMwsn53tncdH-5iLu8-w')\n",
    "channel8_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39a7ad92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'House Of The Dragon',\n",
       " 'channel_id': 'UCfZtSuQt-Krr3jyhOBQBxbg',\n",
       " 'subscriber_count': '144000',\n",
       " 'channel_views': '7265890',\n",
       " 'channel_discription': 'Game Of Thrones Returns Aug 21st as a prequel series on HBO MAX \\n\\n\\nSubscribe for everything Game Of Thrones:\\n\\n‚Ä¢House Of The Dragon\\n‚Ä¢Best of Game of thrones\\n‚Ä¢Latest News And updates\\n‚Ä¢Game of thrones Seasons 1-8\\n‚Ä¢Trailers, teasers, promos, previews\\n‚Ä¢Recaps \\n‚Ä¢History And lore\\n‚Ä¢Fan content\\nAnd much more...',\n",
       " 'playlist_id': 'UUfZtSuQt-Krr3jyhOBQBxbg'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel9_details=get_channel_data('UCfZtSuQt-Krr3jyhOBQBxbg')\n",
    "channel9_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f383364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel_name': 'manichow',\n",
       " 'channel_id': 'UCmrsodcsfoZyFwW_f-ZtvfQ',\n",
       " 'subscriber_count': '219000',\n",
       " 'channel_views': '6960887',\n",
       " 'channel_discription': \"she's a 10 but embarrasses herself on the internet\",\n",
       " 'playlist_id': 'UUmrsodcsfoZyFwW_f-ZtvfQ'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel10_details=get_channel_data('UCmrsodcsfoZyFwW_f-ZtvfQ')\n",
    "channel10_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a34219c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_videos_ids(channel_id):\n",
    "        videos_ids=[]\n",
    "        np_token=None\n",
    "        response = youtube.channels().list(part=\"contentDetails\",\n",
    "                                           id=channel_id).execute()\n",
    "        playlist_id=response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "        while True:\n",
    "            response= youtube.playlistItems().list(\n",
    "                    part=\"snippet\",\n",
    "                    playlistId=playlist_id,\n",
    "                    maxResults=50,\n",
    "                    pageToken=np_token).execute()\n",
    "\n",
    "            for i in range(len(response['items'])):\n",
    "                    videos_ids.append(response['items'][i]['snippet']['resourceId']['videoId'])\n",
    "\n",
    "            np_token=response.get('nextPageToken') \n",
    "\n",
    "            if np_token is None:\n",
    "                break\n",
    "        return videos_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7fa9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_data(videos_ids):\n",
    "        videos_data=[]\n",
    "        for i in videos_ids:\n",
    "                response=youtube.videos().list(part='snippet,contentDetails,statistics',\n",
    "                                         id=i).execute()\n",
    "                for j in response['items']:\n",
    "                    data=dict(channel_name=j['snippet']['channelTitle'],\n",
    "                         video_id=j['id'],\n",
    "                          video_name=j['snippet']['title'],\n",
    "                         video_description=j['snippet']['description'],\n",
    "                         tags=j['snippet'].get('tags'),\n",
    "                         published_at=j['snippet']['publishedAt'],\n",
    "                         view_count=j['statistics']['viewCount'],\n",
    "                         like_count=j['statistics'].get('likeCount'),\n",
    "                         favourite_count=j['statistics']['favoriteCount'],\n",
    "                         comment_count=j['statistics'].get('commentCount'),\n",
    "                         duration=j['contentDetails']['duration'],\n",
    "                         thumbnails=j['snippet']['thumbnails']['default']['url'],\n",
    "                         caption_status=j['contentDetails']['caption'])\n",
    "                videos_data.append(data)\n",
    "        return videos_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8d5563",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_comment_data(video_id):\n",
    "    comment_data=[]   \n",
    "    try:\n",
    "         for i in video_id:\n",
    "                response=youtube.commentThreads().list(part='snippet',\n",
    "                                                                    videoId=i,\n",
    "                                                                    maxResults=50).execute()\n",
    "                for j in response['items']:\n",
    "                            data=dict(comment_id=j['snippet']['topLevelComment']['id'],\n",
    "                                      video_id=j[\"snippet\"][\"videoId\"],\n",
    "                                                 comment_text=j['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "                                                 comment_author=j['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "                                                 comment_publishedat=j['snippet']['topLevelComment']['snippet']['publishedAt'])\n",
    "                            comment_data.append(data)\n",
    "    except:\n",
    "        pass\n",
    "    return comment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97e45b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlist_data(channel_id):\n",
    "        np_token= None\n",
    "        playlist_data=[]\n",
    "        while True:\n",
    "                response=youtube.playlists().list(part='contentDetails,snippet',\n",
    "                                                  channelId=channel_id,\n",
    "                                                 maxResults=50,\n",
    "                                                  pageToken=np_token).execute()\n",
    "                for i in response['items']:\n",
    "                    data=dict(playlist_id=i['id'],\n",
    "                             channel_id=i['snippet']['channelId'],\n",
    "                             channel_name=i['snippet']['channelTitle'],\n",
    "                             playlist_name=i['snippet']['title'])\n",
    "                    playlist_data.append(data)\n",
    "                np_token=response.get('nextPageToken')\n",
    "                if np_token is None:\n",
    "                            break\n",
    "        return playlist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5fe3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "client=pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "database=client[\"YouTube_data_harvesting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9604cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_datas(channel_id):\n",
    "    channel_data=get_channel_data(channel_id)\n",
    "    playlist_data=get_playlist_data(channel_id)\n",
    "    video_id=get_videos_ids(channel_id)\n",
    "    video_data=get_video_data(video_id)\n",
    "    comment_data=get_comment_data(video_id)\n",
    "    \n",
    "    collection=database['channel_data']\n",
    "    collection.insert_one({'channel_information': channel_data,\n",
    "                            'video_information': video_data,\n",
    "                            'comment_information': comment_data,\n",
    "                            'playlist_information': playlist_data})\n",
    "    return \"success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "625af8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_datas('UC_HZY9d5wJ-MEiuq6vhx8hg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11d6d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_datas('UCCAqSErX2Rp-QADZNPfPK6A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c845763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_datas('UCJcCB-QYPIBcbKcBQOTwhiA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16f2bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_datas('UCOc9_2EiEc6XrHZZ1Gupv8g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47f78349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_datas('UCPyFYlqbkxkWX_dWCg0eekA')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17b438d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_datas('UCbq544I2cTyvcrZwmnSIj9Q')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78b3150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_datas('UCYLS9TSah19IsB8yyUpiDzg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be77e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_datas('UC8_aMwsn53tncdH-5iLu8-w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e976204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_datas('UCfZtSuQt-Krr3jyhOBQBxbg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0735efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_datas('UCmrsodcsfoZyFwW_f-ZtvfQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5794e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_channel_table():\n",
    "    db=psycopg2.connect(host='localhost',\n",
    "                       user='postgres',\n",
    "                       password='27112002Cbm!',\n",
    "                       database='YouTube_data_harvesting',\n",
    "                       port='5432')\n",
    "    cursor=db.cursor()\n",
    "    \n",
    "    drop='drop table if exists channels'\n",
    "    cursor.execute(drop)\n",
    "    db.commit()\n",
    "\n",
    "    create='''create table if not exists channels(channel_name VARCHAR(255),\n",
    "    channel_id VARCHAR(255) PRIMARY KEY,\n",
    "    channel_subscribers BIGINT,\n",
    "    channel_views BIGINT,\n",
    "    channel_description TEXT,\n",
    "    playlist_id VARCHAR(255))'''\n",
    "\n",
    "    cursor.execute(create)\n",
    "    db.commit()\n",
    "\n",
    "    database=client[\"YouTube_data_harvesting\"]\n",
    "    collection=database['channel_data']\n",
    "    channel_list=[]\n",
    "    for i in collection.find({},{'_id':0,'channel_information':1}):\n",
    "        channel_list.append(i['channel_information'])\n",
    "    df=pd.DataFrame(channel_list)\n",
    "\n",
    "    for i,j in df.iterrows():\n",
    "        insert='''insert into channels(channel_name,\n",
    "        channel_id,\n",
    "        channel_subscribers,\n",
    "        channel_views,\n",
    "        channel_description,\n",
    "        playlist_id)values(%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "        values=(j['channel_name'],\n",
    "              j['channel_id'],\n",
    "              j['subscriber_count'],\n",
    "              j['channel_views'],\n",
    "              j['channel_discription'],\n",
    "              j['playlist_id'])\n",
    "        cursor.execute(insert,values)\n",
    "        db.commit()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876fc45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9b6ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_playlist_table():\n",
    "    db=psycopg2.connect(host='localhost',\n",
    "                       user='postgres',\n",
    "                       password='27112002Cbm!',\n",
    "                       database='YouTube_data_harvesting',\n",
    "                       port='5432')\n",
    "    cursor=db.cursor()\n",
    "\n",
    "    drop='drop table if exists playlists'\n",
    "    cursor.execute(drop)\n",
    "    db.commit()\n",
    "    create='''create table if not exists playlists(playlist_name VARCHAR(255),\n",
    "                playlist_id VARCHAR(255) PRIMARY KEY,\n",
    "                channel_name VARCHAR(255),\n",
    "                channel_id VARCHAR(255))'''\n",
    "\n",
    "    cursor.execute(create)\n",
    "    db.commit()\n",
    "    database=client[\"YouTube_data_harvesting\"]\n",
    "    collection=database['channel_data']\n",
    "    playlist_list=[]\n",
    "    for i in collection.find({},{'_id':0,'playlist_information':1}):\n",
    "            for j in range(len(i['playlist_information'])):\n",
    "                playlist_list.append(i['playlist_information'][j])\n",
    "    df=pd.DataFrame(playlist_list)\n",
    "\n",
    "    for i,j in df.iterrows():\n",
    "            insert='''insert into playlists(playlist_name,\n",
    "            channel_id,\n",
    "            channel_name,\n",
    "            playlist_id)values(%s,%s,%s,%s)'''\n",
    "\n",
    "            values=(j['playlist_name'],\n",
    "                  j['channel_id'],\n",
    "                  j['channel_name'],\n",
    "                  j['playlist_id'])\n",
    "\n",
    "            cursor.execute(insert,values)\n",
    "            db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4458a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_table():\n",
    "    db=psycopg2.connect(host='localhost',\n",
    "                       user='postgres',\n",
    "                       password='27112002Cbm!',\n",
    "                       database='YouTube_data_harvesting',\n",
    "                       port='5432')\n",
    "    cursor=db.cursor()\n",
    "\n",
    "    drop='drop table if exists videos'\n",
    "    cursor.execute(drop)\n",
    "    db.commit()\n",
    "\n",
    "    create='''create table if not exists videos(channel_name VARCHAR(255),\n",
    "                    video_id VARCHAR(255) PRIMARY KEY,\n",
    "                    video_name VARCHAR(255),\n",
    "                    video_description TEXT,\n",
    "                    tags TEXT,\n",
    "                    published_at TIMESTAMP,\n",
    "                    view_count BIGINT,\n",
    "                    like_count BIGINT,\n",
    "                    favourite_count INT,\n",
    "                    comment_count INT,\n",
    "                    duration INTERVAL,\n",
    "                    thumbnails VARCHAR(255),\n",
    "                    caption_status VARCHAR(100))'''\n",
    "\n",
    "    cursor.execute(create)\n",
    "    db.commit()\n",
    "\n",
    "    database=client[\"YouTube_data_harvesting\"]\n",
    "    collection=database['channel_data']\n",
    "    videos_list=[]\n",
    "    for i in collection.find({},{'_id':0,'video_information':1}):\n",
    "            for j in range(len(i['video_information'])):\n",
    "                videos_list.append(i['video_information'][j])\n",
    "    df=pd.DataFrame(videos_list)\n",
    "\n",
    "    for i,j in df.iterrows():\n",
    "            insert='''insert into videos(channel_name,\n",
    "                video_id,\n",
    "                video_name,\n",
    "                video_description,\n",
    "                tags,\n",
    "                published_at,\n",
    "                view_count,\n",
    "                like_count,\n",
    "                favourite_count,\n",
    "                comment_count,\n",
    "                duration,\n",
    "                thumbnails,\n",
    "                caption_status)values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)'''\n",
    "\n",
    "            values=(j['channel_name'],\n",
    "                  j['video_id'],\n",
    "                  j['video_name'],\n",
    "                  j['video_description'],\n",
    "                    j['tags'],\n",
    "                  j['published_at'],\n",
    "                  j['view_count'],\n",
    "                  j['like_count'],\n",
    "                  j['favourite_count'],\n",
    "                  j['comment_count'],\n",
    "                  j['duration'],\n",
    "                  j['thumbnails'],\n",
    "                    j['caption_status'])\n",
    "\n",
    "            cursor.execute(insert,values)\n",
    "            db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680b85b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d225994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comment_table():\n",
    "    db=psycopg2.connect(host='localhost',\n",
    "                       user='postgres',\n",
    "                       password='27112002Cbm!',\n",
    "                       database='YouTube_data_harvesting',\n",
    "                       port='5432')\n",
    "    cursor=db.cursor()\n",
    "\n",
    "    drop='drop table if exists comments'\n",
    "    cursor.execute(drop)\n",
    "    db.commit()\n",
    "\n",
    "    create='''create table if not exists comments(comment_id VARCHAR(255) PRIMARY KEY,\n",
    "                                                video_id VARCHAR(255),\n",
    "                                                 comment_text TEXT,\n",
    "                                                 comment_author VARCHAR(255),\n",
    "                                                 comment_publishedat TIMESTAMP)'''\n",
    "\n",
    "    cursor.execute(create)\n",
    "    db.commit()\n",
    "\n",
    "    database=client[\"YouTube_data_harvesting\"]\n",
    "    collection=database['channel_data']\n",
    "    comments_list=[]\n",
    "    for i in collection.find({},{'_id':0,'comment_information':1}):\n",
    "            for j in range(len(i['comment_information'])):\n",
    "                comments_list.append(i['comment_information'][j])\n",
    "    df=pd.DataFrame(comments_list)\n",
    "\n",
    "    for i,j in df.iterrows():\n",
    "            insert='''insert into comments(comment_id,\n",
    "                                        video_id,\n",
    "                                         comment_text,\n",
    "                                         comment_author,\n",
    "                                         comment_publishedat)\n",
    "                                         values(%s,%s,%s,%s,%s)'''\n",
    "\n",
    "            values=(j['comment_id'],\n",
    "                    j['video_id'],\n",
    "                  j['comment_text'],\n",
    "                  j['comment_author'],\n",
    "                  j['comment_publishedat'])\n",
    "\n",
    "            cursor.execute(insert,values)\n",
    "            db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e4b362dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tables():\n",
    "    create_channel_table()\n",
    "    create_playlist_table()\n",
    "    create_video_table()\n",
    "    create_comment_table()\n",
    "    \n",
    "    return \"success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3568598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channels_table():\n",
    "        database=client[\"YouTube_data_harvesting\"]\n",
    "        collection=database['channel_data']\n",
    "        channel_list=[]\n",
    "        for i in collection.find({},{'_id':0,'channel_information':1}):\n",
    "            channel_list.append(i['channel_information'])\n",
    "        df=sl.dataframe(channel_list)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d39bc04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_playlists_table():\n",
    "        database=client[\"YouTube_data_harvesting\"]\n",
    "        collection=database['channel_data']\n",
    "        playlist_list=[]\n",
    "        for i in collection.find({},{'_id':0,'playlist_information':1}):\n",
    "                for j in range(len(i['playlist_information'])):\n",
    "                    playlist_list.append(i['playlist_information'][j])\n",
    "        df=sl.dataframe(playlist_list)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f46f9ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_videos_table():\n",
    "        database=client[\"YouTube_data_harvesting\"]\n",
    "        collection=database['channel_data']\n",
    "        videos_list=[]\n",
    "        for i in collection.find({},{'_id':0,'video_information':1}):\n",
    "                for j in range(len(i['video_information'])):\n",
    "                    videos_list.append(i['video_information'][j])\n",
    "        df=sl.dataframe(videos_list)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d56938b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_comments_table():\n",
    "        database=client[\"YouTube_data_harvesting\"]\n",
    "        collection=database['channel_data']\n",
    "        comments_list=[]\n",
    "        for i in collection.find({},{'_id':0,'comment_information':1}):\n",
    "                for j in range(len(i['comment_information'])):\n",
    "                    comments_list.append(i['comment_information'][j])\n",
    "        df=sl.dataframe(comments_list)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6df1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sl.sidebar:\n",
    "    sl.title(\":red[YOUTUBE DATA HARVESTING AND WAREHOUSING]\")\n",
    "    sl.markdown(\"CAPSTONE I (GUVI)\")\n",
    "    sl.header(\"SKILL TAKE AWAY\")\n",
    "    sl.caption('Python scripting')\n",
    "    sl.caption(\"Data Collection\")\n",
    "    sl.caption(\"MongoDB\")\n",
    "    sl.caption(\"API Integration\")\n",
    "    sl.caption(\" Data Managment using MongoDB and SQL\")\n",
    "    \n",
    "channel_id=sl.text_input(\"Enter the Channel Id:\")\n",
    "if sl.button(\"store the data\"):\n",
    "    channel_id_list=[]\n",
    "    database=client[\"YouTube_data_harvesting\"]\n",
    "    collection=database['channel_data']\n",
    "    for i in collection.find({},{'_id':0,'channel_information':1}):\n",
    "        channel_id_list.append(i['channel_information']['channel_id'])\n",
    "    \n",
    "    if channel_id in channel_id_list:\n",
    "        sl.success(\"Channel data already exists!\")\n",
    "    else:\n",
    "        insert=channel_datas(channel_id)\n",
    "        sl.success(insert)\n",
    "        \n",
    "if sl.button(\"Migrate to SQL\"):\n",
    "    display = tables()\n",
    "    sl.success(display)\n",
    "    \n",
    "show_table = sl.radio(\"Choose table that has to be displayed\",(\":green[channels]\",\n",
    "                                                   \":orange[playlists]\",\n",
    "                                                   \":red[videos]\",\n",
    "                                                   \":blue[comments]\"))\n",
    "\n",
    "if show_table == \":green[channels]\":\n",
    "    show_channels_table()\n",
    "elif show_table == \":orange[playlists]\":\n",
    "    show_playlists_table()\n",
    "elif show_table ==\":red[videos]\":\n",
    "    show_videos_table()\n",
    "elif show_table == \":blue[comments]\":\n",
    "    show_comments_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a26fb7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UC_HZY9d5wJ-MEiuq6vhx8hg\n",
      "UCJcCB-QYPIBcbKcBQOTwhiA\n"
     ]
    }
   ],
   "source": [
    "db=psycopg2.connect(host='localhost',\n",
    "                   user='postgres',\n",
    "                   password='27112002Cbm!',\n",
    "                   database='YouTube_data_harvesting',\n",
    "                   port='5432')\n",
    "cursor=db.cursor()\n",
    "\n",
    "question = sl.selectbox(\n",
    "    'Please Select Your Question',\n",
    "    ('1. Names of all the videos and their corresponding channels',\n",
    "     '2. Channels having the most number of videos',\n",
    "     '3. Top 10 most viewed videos and their respective channels',\n",
    "     '4. No. of comments made on each video and their corresponding video names',\n",
    "     '5. Videos having the highest number of likes and their corresponding channel names',\n",
    "     '6. Total number of likes and dislikes for each video and their corresponding video names',\n",
    "     '7. Total number of views for each channel, and their corresponding channel names',\n",
    "     '8. Names of all the channels that have published videos in the year 2022',\n",
    "     '9. Average duration of all videos in each channel and their corresponding channel names',\n",
    "     '10. Videos have the highest number of comments and their corresponding channel names'))\n",
    "\n",
    "     \n",
    "if question == '1. All the videos and the Channel Name':\n",
    "    query1 = \"select Title as videos, Channel_Name as ChannelName from videos;\"\n",
    "    cursor.execute(query1)\n",
    "    mydb.commit()\n",
    "    t1=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t1, columns=[\"Video Title\",\"Channel Name\"]))\n",
    "\n",
    "elif question == '2. Channels with most number of videos':\n",
    "    query2 = \"select Channel_Name as ChannelName,Total_Videos as NO_Videos from channels order by Total_Videos desc;\"\n",
    "    cursor.execute(query2)\n",
    "    mydb.commit()\n",
    "    t2=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t2, columns=[\"Channel Name\",\"No Of Videos\"]))\n",
    "\n",
    "elif question == '3. 10 most viewed videos':\n",
    "    query3 = '''select Views as views , Channel_Name as ChannelName,Title as VideoTitle from videos \n",
    "                        where Views is not null order by Views desc limit 10;'''\n",
    "    cursor.execute(query3)\n",
    "    mydb.commit()\n",
    "    t3 = cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t3, columns = [\"views\",\"channel Name\",\"video title\"]))\n",
    "\n",
    "elif question == '4. Comments in each video':\n",
    "    query4 = \"select Comments as No_comments ,Title as VideoTitle from videos where Comments is not null;\"\n",
    "    cursor.execute(query4)\n",
    "    mydb.commit()\n",
    "    t4=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t4, columns=[\"No Of Comments\", \"Video Title\"]))\n",
    "\n",
    "elif question == '5. Videos with highest likes':\n",
    "    query5 = '''select Title as VideoTitle, Channel_Name as ChannelName, Likes as LikesCount from videos \n",
    "                       where Likes is not null order by Likes desc;'''\n",
    "    cursor.execute(query5)\n",
    "    mydb.commit()\n",
    "    t5 = cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t5, columns=[\"video Title\",\"channel Name\",\"like count\"]))\n",
    "\n",
    "elif question == '6. likes of all videos':\n",
    "    query6 = '''select Likes as likeCount,Title as VideoTitle from videos;'''\n",
    "    cursor.execute(query6)\n",
    "    mydb.commit()\n",
    "    t6 = cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t6, columns=[\"like count\",\"video title\"]))\n",
    "\n",
    "elif question == '7. views of each channel':\n",
    "    query7 = \"select Channel_Name as ChannelName, Views as Channelviews from channels;\"\n",
    "    cursor.execute(query7)\n",
    "    mydb.commit()\n",
    "    t7=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t7, columns=[\"channel name\",\"total views\"]))\n",
    "\n",
    "elif question == '8. videos published in the year 2022':\n",
    "    query8 = '''select Title as Video_Title, Published_Date as VideoRelease, Channel_Name as ChannelName from videos \n",
    "                where extract(year from Published_Date) = 2022;'''\n",
    "    cursor.execute(query8)\n",
    "    mydb.commit()\n",
    "    t8=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t8,columns=[\"Name\", \"Video Publised On\", \"ChannelName\"]))\n",
    "\n",
    "elif question == '9. average duration of all videos in each channel':\n",
    "    query9 =  \"SELECT Channel_Name as ChannelName, AVG(Duration) AS average_duration FROM videos GROUP BY Channel_Name;\"\n",
    "    cursor.execute(query9)\n",
    "    mydb.commit()\n",
    "    t9=cursor.fetchall()\n",
    "    t9 = pd.DataFrame(t9, columns=['ChannelTitle', 'Average Duration'])\n",
    "    T9=[]\n",
    "    for index, row in t9.iterrows():\n",
    "        channel_title = row['ChannelTitle']\n",
    "        average_duration = row['Average Duration']\n",
    "        average_duration_str = str(average_duration)\n",
    "        T9.append({\"Channel Title\": channel_title ,  \"Average Duration\": average_duration_str})\n",
    "    st.write(pd.DataFrame(T9))\n",
    "\n",
    "elif question == '10. videos with highest number of comments':\n",
    "    query10 = '''select Title as VideoTitle, Channel_Name as ChannelName, Comments as Comments from videos \n",
    "                       where Comments is not null order by Comments desc;'''\n",
    "    cursor.execute(query10)\n",
    "    mydb.commit()\n",
    "    t10=cursor.fetchall()\n",
    "    st.write(pd.DataFrame(t10, columns=['Video Title', 'Channel Name', 'NO Of Comments']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac14357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
